{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90640cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from model import IMPALAFruitfly\n",
    "import torch\n",
    "import os, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from ray.air import Checkpoint\n",
    "from ray.rllib.models import ModelCatalog\n",
    "import ray\n",
    "from model import IMPALAFruitfly\n",
    "import pickle5 as pickle\n",
    "from wordcloud import WordCloud\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import gym\n",
    "from tabulate import tabulate\n",
    "from ray.rllib.algorithms import impala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e58aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#W = torch.load('/pvc/privatefs/afigueroa/fruitfly/models/2022_03_18__133640846698_587934f6/checkpoint_19.pth', map_location='cpu')\n",
    "cpu_path = '/pvc/privatefs/afigueroa/fruitfly/models/2022_03_18__133640846698_587934f6/checkpoint_19_cpu.pth'\n",
    "#torch.save(W, cpu_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85d87d",
   "metadata": {},
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.recurrent_net import RecurrentNetwork as TorchRNN\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.models.modelv2 import ModelV2\n",
    "from ray.rllib.models.modelv2 import ModelV2, restore_original_dimensions\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class IMPALAFruitfly(TorchModelV2, nn.Module):\n",
    "#class IMPALAFruitfly(TorchRNN, nn.Module):\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name, K, k, tokenizer_name=\"bert-base-uncased\", model_path=None):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "      \n",
    "        config = AutoConfig.from_pretrained(tokenizer_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=True)#Debugging TODO: REMOVE\n",
    "        self.sample_count = 0 #Debugging TODO: REMOVE\n",
    "        self.config = model_config\n",
    "        self.K = K\n",
    "        self.k = k\n",
    "        #self.lstm = torch.nn.LSTM(K, 256, batch_first=True) \n",
    "        if model_path is not None:\n",
    "            self.W = torch.load(model_path)\n",
    "            #self.W.requires_grad=False\n",
    "            self.vocab_size = self.W.shape[-1]//2\n",
    "        else:\n",
    "            self.vocab_size = config.vocab_size\n",
    "            self.W = torch.nn.Parameter(torch.randn(K, 2*self.vocab_size, dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "        self.observation_space = obs_space\n",
    "        self.action_space = action_space\n",
    "        self.window_size = 11\n",
    "        self.e_weight = 0.999 # Weight of energy custom loss\n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "\n",
    "\n",
    "        self.action_outputs = nn.Linear(K, num_outputs)\n",
    "        #self.action_outputs = nn.Linear(256, num_outputs)\n",
    "\n",
    "        self.value_network = nn.Linear(K, 1)\n",
    "        #self.value_network = nn.Linear(256, 1)\n",
    "        self.fs = torch.nn.Parameter(torch.ones(self.vocab_size), requires_grad=False) #Acumulated frequencies of tokens\n",
    "        self._features = None\n",
    "        #def debug_fn(grads):\n",
    "        #    return grads*1e6\n",
    "\n",
    "        #self.encoder.W.register_hook(debug_fn)\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict: Dict, state: List, seq_lens: Any):\n",
    "        ids = input_dict[\"obs\"].squeeze(1) \n",
    "        \n",
    "        ids = torch.cat((ids, ids+self.vocab_size), dim=1) # Add the ids to the target part of the sparse vector \n",
    "        full_sequence_batch_indices = torch.arange(0, len(ids), dtype=torch.int32).repeat_interleave(input_dict[\"obs\"].shape[-1]).to(input_dict['obs'].device)\n",
    "        full_sequence_coordinates = torch.stack((full_sequence_batch_indices, input_dict[\"obs\"].reshape(-1))).T\n",
    "        # Mask out the [PAD] tokens by setting their value to 0, coalesce to shrink the nnzs\n",
    "        #sparse_values = torch.ones_like(full_sequence_coordinates.T[0])*(input_dict['obs']!=0).reshape(full_sequence_coordinates.T[0].shape) \n",
    "        sparse_values = torch.ones_like(full_sequence_coordinates.T[0]).reshape(full_sequence_coordinates.T[0].shape) \n",
    "        out_V_A_s = torch.sparse_coo_tensor(full_sequence_coordinates.T, sparse_values, (ids.shape[0], 2*self.vocab_size), dtype=torch.float32).coalesce()\n",
    "\n",
    "        activations = torch.sparse.mm(out_V_A_s, self.W.T)\n",
    "        self._features = activations\n",
    "        \n",
    "        binary_hash = torch.zeros_like(activations, dtype=torch.bool)\n",
    "        order = activations.argsort(dim=1, descending=True)\n",
    "        trues = order[:,:self.k]\n",
    "        binary_hash = binary_hash.scatter_(dim=1, index = trues, src=torch.ones_like(trues, dtype=torch.bool))\n",
    "\n",
    "        logits = self.activation(self.action_outputs(binary_hash.float()))\n",
    "        return  logits, state\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def custom_loss(self, policy_loss, loss_inputs):\n",
    "        ids = loss_inputs[\"obs\"].squeeze(1)\n",
    "\n",
    "        # Updating the frequency of the tokens\n",
    "        if self.sample_count < 1e9:\n",
    "          full_sequence_batch_indices = torch.arange(0, len(ids), dtype=torch.int32).repeat_interleave(loss_inputs[\"obs\"].shape[-1]).to(loss_inputs['obs'].device)\n",
    "          full_sequence_coordinates = torch.stack((full_sequence_batch_indices, loss_inputs[\"obs\"].reshape(-1))).T\n",
    "          out_V_A_s = torch.sparse_coo_tensor(full_sequence_coordinates.T, torch.ones_like(full_sequence_coordinates.T[0]), (ids.shape[0], 2*self.vocab_size), dtype=torch.float32)\n",
    "          fs = torch.sparse.sum(out_V_A_s, dim=0)\n",
    "          self.fs[fs.indices().squeeze()] += fs.values()\n",
    "\n",
    "        input_ids = ids.unfold(1, self.window_size, 1).clone().reshape(-1, self.window_size)\n",
    "        input_ids[:,(self.window_size//2)] += self.vocab_size \n",
    "        indices_batch = torch.arange(0,len(input_ids), dtype=torch.int32).repeat_interleave(self.window_size).to(input_ids.device)\n",
    "        coordinates = torch.stack((indices_batch, input_ids.reshape(-1))).T\n",
    "\n",
    "        Ps = 1/self.fs[coordinates.T[1]%self.vocab_size].reshape(input_ids.shape[0], input_ids.shape[1])\n",
    "        batch_size = input_ids.shape[0] # Batch size in the sense of the windowed sequences\n",
    "        # Mask out the values of the [PAD] tokens, coalesce the sparse tensor to reduce the number of mms, coalesce() to reduce the nnz hence the multiplications of repeated tokens\n",
    "        sparse_values = torch.logical_and(input_ids!=0,input_ids!=self.vocab_size).float().reshape(coordinates.T[0].shape)\n",
    "        \n",
    "        V_A_s = torch.sparse_coo_tensor(coordinates.T,torch.ones_like(coordinates.T[0]),(batch_size,2*self.vocab_size),dtype=torch.float32).coalesce()#.to_sparse_csr()\n",
    "        #breakpoint()\n",
    "        #Inv_P_s = torch.sparse_coo_tensor(coordinates.T,Ps.reshape(-1),(batch_size,2*self.vocab_size),dtype=torch.float32)#.to_sparse_csr()\n",
    "\n",
    "        V_AxWT = torch.sparse.mm(V_A_s, self.W.T)\n",
    "        mu = V_AxWT.argmax(axis=1)\n",
    "        W_mu_nonzero = torch.gather(self.W[mu], 1, coordinates.T[1].reshape(batch_size,-1))\n",
    "        alpha = (W_mu_nonzero*Ps).sum(axis=1)\n",
    "        denominator = torch.linalg.norm(self.W, dim = 1)[mu]\n",
    "        E = -(alpha/denominator).sum() \n",
    "        self.fruit_fly_energy_metric = E.item()\n",
    "        self.fruit_fly_energy_inverse_metric = 1/(E.item())\n",
    "        self.policy_loss_metric = np.mean([loss.item() for loss in policy_loss])\n",
    "        \n",
    "        self.sample_count +=1\n",
    "        #if self.sample_count == 10:\n",
    "        #    breakpoint()\n",
    "        return [(1 - self.e_weight)*loss_+ self.e_weight*E for loss_ in policy_loss]\n",
    "        #return [E] + policy_loss\n",
    "\n",
    "    @override(TorchModelV2)    \n",
    "    def value_function(self):\n",
    "        assert self._features is not None, \"Must call forward first\"\n",
    "        #return torch.reshape(self._E*self.activation(self.value_network(self._features)), [-1])\n",
    "        return torch.reshape(self.activation(self.value_network(self._features)), [-1])\n",
    "\n",
    "    def metrics(self):\n",
    "        return {\n",
    "                'policy_loss': self.policy_loss_metric,\n",
    "                'fruit_fly_energy':self.fruit_fly_energy_metric,\n",
    "                'fruit_fly_energy_inverse':self.fruit_fly_energy_inverse_metric\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f293a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids2English(tokenizer):\n",
    "    \"\"\"\n",
    "    Closure that returns a function to translate token ids to english given\n",
    "    a tokenizer.\n",
    "    \"\"\"\n",
    "    full_vocab = copy.deepcopy(tokenizer.vocab)\n",
    "    #full_vocab.update(tokenizer.added_tokens_encoder.items())\n",
    "    vocab_inv = { v:k for k,v in full_vocab.items()}\n",
    "    \n",
    "    #special_tokens = SPECIAL_TOKENS\n",
    "    special_tokens = []\n",
    "    special_token_ids = [full_vocab[t.lower()] for t in special_tokens]\n",
    "    special_tokens +=['-100 MASK', '[CLS]', '[PAD]', '[MASK]']\n",
    "    special_token_ids += [-100, full_vocab['[CLS]'], full_vocab['[PAD]'], full_vocab['[MASK]']]\n",
    "\n",
    "    def parser(input_ids):\n",
    "        res = []\n",
    "        i = 0\n",
    "        while i < len(input_ids):\n",
    "            t = input_ids[i]\n",
    "            if t in special_token_ids:\n",
    "                token_str = special_tokens[special_token_ids.index(t)]\n",
    "                repetitions = 0\n",
    "                while i < len(input_ids) and input_ids[i] == t:\n",
    "                    repetitions += 1\n",
    "                    i += 1  \n",
    "                # Trim the []\n",
    "                token_str = token_str.replace('[','')\n",
    "                token_str = token_str.replace(']','')\n",
    "                \n",
    "                if repetitions == 1:\n",
    "                    res.append(f\"[{token_str}]\")\n",
    "                if repetitions > 1:\n",
    "                    res.append(f\"[{repetitions}X {token_str}]\")\n",
    "            else:\n",
    "                res.append(vocab_inv[t])\n",
    "                i += 1\n",
    "        return \" \".join(res)\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b5042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_base_url = '/root/ray_results/bert-base-uncased-None/IMPALA_gym_medical:doctorsim-v0_d238e_00000_0_2022-09-07_13-41-48'\n",
    "checkpoint_base_url = '/root/ray_results/bert-base-uncased-1/IMPALA_gym_medical:doctorsim-v0_fad65_00000_0_2022-09-16_09-43-12'\n",
    "checkpoint_base_url = '/root/ray_results/bert-base-uncased-1/IMPALA_gym_medical:doctorsim-v0_328e6_00000_0_2022-09-19_11-50-03'\n",
    "checkpoint_base_url = '/root/ray_results/bert-base-uncased-1/IMPALA_gym_medical:doctorsim-v0_2c5ba_00000_0_2022-09-19_12-54-18'\n",
    "checkpoint_base_url = '/root/ray_results/bert-base-uncased-1/IMPALA_gym_medical:doctorsim-v0_5449c_00000_0_2022-09-19_13-31-13'\n",
    "checkpoint_base_url = '/root/ray_results/bert-base-uncased-1/IMPALA_gym_medical:doctorsim-v0_b0521_00000_0_2022-09-19_15-49-47'\n",
    "checkpoint_base_url = '/root/ray_results/bert-base-uncased-1/IMPALA_gym_medical:doctorsim-v0_a8108_00000_0_2022-09-19_16-53-59'\n",
    "checkpoint_base_url = '/pvc/privatefs/data/ray_results/bert-base-uncased-1/IMPALA_gym_medical:doctorsim-v0_85293_00000_0_2022-10-07_09-00-41'\n",
    "checkpoint_base_url = '/pvc/privatefs/data/ray_results/bert-base-uncased-1/IMPALA_gym_medical:doctorsim-v0_557b3_00000_0_2022-10-31_10-46-54'\n",
    "checkpoint_base_url = '/pvc/privatefs/data/ray_results/bert-base-uncased-None/IMPALA_gym_medical:doctorsim-v0_1a51d_00000_0_2022-10-31_14-55-47' #Still with [PAD] bug\n",
    "#checkpoint_base_url = '/pvc/privatefs/data/ray_results/bert-base-uncased-None/IMPALA_gym_medical:doctorsim-v0_108df_00000_0_2022-11-04_15-05-05'\n",
    "checkpoint_base_url = '/pvc/privatefs/data/ray_results/bert-base-uncased-None/IMPALA_gym_medical:doctorsim-v0_bd510_00000_0_2022-11-11_16-13-12'\n",
    "checkpoint_base_url = '/pvc/privatefs/data/ray_results/bert-base-uncased-None/IMPALA_gym_medical:doctorsim-v0_7c391_00000_0_2022-11-15_11-41-47'\n",
    "checkpoint_base_url = '/pvc/privatefs/data/ray_results/bert-base-uncased-10/IMPALA_gym_medical:doctorsim-v0_e2115_00000_0_2022-11-15_15-55-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b32c2d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/pvc/privatefs/data/ray_results/bert-base-uncased-None/IMPALA_gym_medical:doctorsim-v0_e2115_00000_0_2022-11-15_15-55-10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_287712/4229054013.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_base_url\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/pvc/privatefs/data/ray_results/bert-base-uncased-None/IMPALA_gym_medical:doctorsim-v0_e2115_00000_0_2022-11-15_15-55-10'"
     ]
    }
   ],
   "source": [
    "cps = list(map(lambda x: int(x.split('_')[-1]), [e for e in os.listdir(checkpoint_base_url) if e.find('checkpoint')!=-1]))\n",
    "first, last = min(cps), max(cps)\n",
    "first, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95688b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46226a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner = ray.tune.Tuner.restore('/root/ray_results/bert-base-uncased-None/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars(tuner._local_tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoint_base_url + '/params.json' ) as cfg:\n",
    "    ex_config = json.load(cfg)\n",
    "ex_config['model']['custom_model_config']['model_path']=cpu_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977c2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263bd33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model('IMPALAFruitfly',IMPALAFruitfly)\n",
    "\n",
    "config = impala.ImpalaConfig()\n",
    "config = config.framework('torch').\\\n",
    "            environment(env=\"gym_medical:doctorsim-v0\", env_config = ex_config['env_config']).\\\n",
    "            resources(num_gpus=0, num_gpus_per_worker=0)\n",
    "config.model = ex_config['model']\n",
    "#config.callbacks=actionCallbacks\n",
    "#config.custom_model_config['model_path']=cpu_path\n",
    "#vars(config)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeccb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.restore(checkpoint_base_url + f'/checkpoint_{last:06}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"gym_medical:doctorsim-v0\", **ex_config['env_config'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.tensor(algorithm.get_policy().get_weights()['W'])\n",
    "action_weights = torch.tensor(algorithm.get_policy().get_weights()['action_outputs.weight'])\n",
    "action_bias_weights = torch.tensor(algorithm.get_policy().get_weights()['action_outputs.bias'])\n",
    "vocab_size = len(tokenizer)\n",
    "def synapse_order(prompt, W, vocab_size):\n",
    "    \n",
    "    #ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    ids = prompt\n",
    "    #print(ids)\n",
    "    ids = torch.cat( ( torch.tensor(ids), torch.tensor(ids) + vocab_size) ) #KNOWN BUG\n",
    "    #ids = torch.tensor(ids)\n",
    "    \n",
    "    coordinates = torch.stack((torch.zeros_like(ids), ids)).T\n",
    "    sparse_values = torch.ones_like(ids)*(ids!=0)*(ids!=vocab_size)\n",
    "    V_A_s = torch.sparse_coo_tensor(coordinates.T, \n",
    "                                    #torch.ones_like(ids), \n",
    "                                    sparse_values,\n",
    "                                    (1,2*vocab_size), dtype=torch.float).coalesce()\n",
    "    V_AxWT = torch.sparse.mm(V_A_s, W.T)\n",
    "    activation_order = V_AxWT.squeeze().argsort(descending=True)\n",
    "    return activation_order, V_AxWT\n",
    "\n",
    "def top_neuron_words(n_neurons, top_n_words, W, activation_order, tokenizer):\n",
    "    wcs = []\n",
    "    wcs_dict = []\n",
    "    vocab = len(tokenizer)\n",
    "    for NEURON in activation_order[:n_neurons]:\n",
    "        synapses = W[NEURON][:vocab]\n",
    "        #synapses = W[NEURON][vocab:] \n",
    "        #synapses = torch.nn.functional.softmax(synapses)\n",
    "        order = synapses.argsort(descending=True) #Important words in the neuron\n",
    "        neuron = defaultdict(list)\n",
    "        neuron_synapses = defaultdict(list)\n",
    "        for i, e in enumerate(order[:top_n_words]):\n",
    "            neuron_synapses[NEURON.item()].append((e.item(), tokenizer.decode(e.item()), synapses[e].item()))\n",
    "            neuron[NEURON.item()].append(tokenizer.decode(e.item()))\n",
    "        wcs_dict.append(neuron_synapses)\n",
    "        wcs.append(neuron)\n",
    "    return wcs, wcs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash2str(ff_hash, w, h):\n",
    "    res = ''\n",
    "    for i,value in enumerate(ff_hash):\n",
    "        if i%w == 0:\n",
    "            res +='\\n'\n",
    "        if value:\n",
    "            res +='●'\n",
    "        else:\n",
    "            res += '○'\n",
    "            \n",
    "    return res\n",
    "h = torch.rand(400)>0.8\n",
    "print(hash2str(h,50,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithm.compute_single_action(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90cf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b294fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = ids2English(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c5d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "#state = [torch.zeros((1, 256)).squeeze(0),torch.zeros((1, 256)).squeeze(0)]\n",
    "done = False\n",
    "i = 0\n",
    "episode = []\n",
    "while not done:\n",
    "    #DIA_ATF\n",
    "    #DIA_LIN\n",
    "    #if env.get_patient().disease.id != 'DIA_ATF':\n",
    "    #    s = env.reset()\n",
    "    #    continue\n",
    "    #print(f'===========================iteration :{i} Done :[{done}] ===============================')\n",
    "    #env.render()\n",
    "    \n",
    "    #print(f'Current state: {eng(s)}\\n')\n",
    "    a = algorithm.compute_action(s)\n",
    "    activation_order, V_AxWT = synapse_order(s, W, vocab_size)\n",
    "    binary_hash = torch.zeros_like(V_AxWT, dtype=torch.bool)\n",
    "    order = V_AxWT.squeeze().argsort(descending=True)\n",
    "    trues = order[:50].unsqueeze(0)\n",
    "    binary_hash = binary_hash.scatter_(dim=1, index = trues, src=torch.ones_like(trues, dtype=torch.bool))\n",
    "    \n",
    "    \n",
    "    # Weight the activation order by the action layer, the hash is just ones\n",
    "    \n",
    "    #weighted_activation_order = (V_AxWT.squeeze() * action_weights[a]).argsort(descending=True)\n",
    "    weighted_activation_order = (binary_hash.squeeze(0) * (action_weights[a] + action_bias_weights[a])).argsort(descending=True)\n",
    "    #plt.plot(binary_hash.squeeze(0) * (action_weights[a] + action_bias_weights[a]), label = f'step {i}')\n",
    "    \n",
    "    tw,wcs_dict = top_neuron_words(6,\n",
    "                          20,\n",
    "                          W, \n",
    "                          activation_order,\n",
    "                          #weighted_activation_order,\n",
    "                          tokenizer)\n",
    "    for neuron in tw:\n",
    "        top_words = ''\n",
    "        for k,v in neuron.items():\n",
    "            top_words+= f'{k}: ' + ' '.join(v)\n",
    "        \n",
    "        #print(top_words)\n",
    "    #print('--------------------weighted--activations-----')    \n",
    "    wtw, w_wcs_dict = top_neuron_words(6,\n",
    "                          20,\n",
    "                          W, \n",
    "                          #activation_order,\n",
    "                          weighted_activation_order,\n",
    "                          tokenizer)\n",
    "    for neuron in wtw:\n",
    "        top_words = ''\n",
    "        for k,v in neuron.items():\n",
    "            top_words+= f'{k}: ' + ' '.join(v)\n",
    "        \n",
    "        #print(top_words)\n",
    "\n",
    "    #print(f'Algorithm action: {a}')\n",
    "    episode.append((f'Current state: {eng(s)}\\n',wcs_dict, binary_hash.squeeze(0) * (action_weights[a] + action_bias_weights[a])))\n",
    "    #episode.append((f'Current state: {eng(s)}\\n',wcs_dict, activation_order))\n",
    "    s, r, done, info = env.step(a)\n",
    "    #print(r)\n",
    "     \n",
    "    i+=1\n",
    "    if done and i>10:\n",
    "        done=False\n",
    "        s=env.reset()\n",
    "        episode=[]\n",
    "        i=0\n",
    "print(f'===========================iteration :{i} Done :[{done}] ===============================')\n",
    "env.render()\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61b253",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    " \n",
    "\n",
    "for i_episode, (current_state, episode_step, weighted_activation_order) in enumerate(episode[:9]):\n",
    "    #figure(figsize=(30,30), dpi=600, facecolor='w', edgecolor='k')\n",
    "    fig, axes = plt.subplots(len(episode_step)//3,3, figsize=(10,10), dpi=100, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    \n",
    "    fig.suptitle(f'Episode step :{i_episode} {current_state}')\n",
    "    for neuron, ax in zip(episode_step, axes.reshape(-1)):\n",
    "        cloud_data = defaultdict(float)\n",
    "        wc = WordCloud(width=256, height=256,background_color='white',max_words=20)\n",
    "        for k, v in neuron.items():\n",
    "            for tokenid, word, synapse_weight in v:\n",
    "                cloud_data[word]=synapse_weight\n",
    "            #ax.set_title(k)\n",
    "        wc.generate_from_frequencies(cloud_data)\n",
    "        ax.imshow(wc, interpolation=\"bilinear\")\n",
    "        ax.axis(\"off\")\n",
    "plt.tight_layout(pad=0)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9185701",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    " \n",
    "\n",
    "for i_episode, (current_state, episode_step, weighted_activation_order) in enumerate(episode[:3]):\n",
    "    fig, axes = plt.subplots(1,1, figsize=(8,8), dpi=100, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(f'Episode step :{i_episode} {current_state}')\n",
    "    cloud_data = defaultdict(float)\n",
    "    wc = WordCloud(width=256, height=256,background_color='white',max_words=1000)\n",
    "    for i_neuron, neuron in enumerate(episode_step):\n",
    "        \n",
    "        for k, v in neuron.items():\n",
    "            \n",
    "            #print(k, weighted_activation_order[k])\n",
    "            for tokenid, word, synapse_weight in v:\n",
    "                cloud_data[word]=(synapse_weight*weighted_activation_order[k]).float().item()\n",
    "                #cloud_data[word]= synapse_weight\n",
    "    #ax.set_title(k)\n",
    "    wc.generate_from_frequencies(cloud_data)\n",
    "    axes.imshow(wc, interpolation=\"bilinear\")\n",
    "    axes.axis(\"off\")\n",
    "plt.tight_layout(pad=0)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe13ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(action_weights, cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11937b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c325f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "done = False\n",
    "i = 0\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(tokenizer, prompt, W, vocab_size, action_weights, bias_weights):\n",
    "    \n",
    "    #ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "    ids = prompt\n",
    "    #print(ids)\n",
    "    #ids = torch.cat( ( torch.tensor(ids), torch.tensor(ids) + vocab_size) )\n",
    "    ids = torch.tensor(ids) # THIS IS A BUG, half of the model isn't used\n",
    "    coordinates = torch.stack((torch.zeros_like(ids), ids)).T\n",
    "    sparse_values = torch.ones_like(ids)#*(ids!=0)#*(ids!=vocab_size)\n",
    "    V_A_s = torch.sparse_coo_tensor(coordinates.T, \n",
    "                                    #torch.ones_like(ids), \n",
    "                                    sparse_values,\n",
    "                                    (1,2*vocab_size), dtype=torch.float).coalesce()\n",
    "    V_AxWT = torch.sparse.mm(V_A_s, W.T)\n",
    "    \n",
    "    binary_hash = torch.zeros_like(V_AxWT, dtype=torch.bool)\n",
    "    order = V_AxWT.squeeze().argsort(descending=True)\n",
    "    trues = order[:50].unsqueeze(0)\n",
    "    print(trues.shape, binary_hash.shape)\n",
    "    binary_hash = binary_hash.scatter_(dim=1, index = trues, src=torch.ones_like(trues, dtype=torch.bool))\n",
    "    logits = torch.matmul(binary_hash.float(), action_weights.T) + bias_weights\n",
    "    logits = torch.nn.GELU()(logits)\n",
    "    action = logits.argmax()\n",
    "    return binary_hash, V_AxWT, logits, action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc81e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binary_hash, V_AxWT, logits, action = forward(tokenizer, torch.tensor(s),W, vocab_size, action_weights, action_bias_weights )\n",
    "a, states, action_stuff = algorithm.compute_action(s, full_fetch=True)\n",
    "print(a, action)\n",
    "plt.plot(logits.squeeze(0))\n",
    "plt.plot(action_stuff['action_dist_inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7078122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399157b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_hash.shape, logits.shape, action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Current state: {eng(s)}\\n')\n",
    "a, states, action_stuff = algorithm.compute_action(s, full_fetch=True)\n",
    "\n",
    "#plt.plot(action[a])\n",
    "print(f'Action: {a}')\n",
    "plt.plot(action_stuff['action_dist_inputs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state = [torch.zeros((1, 256)).squeeze(0),torch.zeros((1, 256)).squeeze(0)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tw =     top_neuron_words(5,\n",
    "                          5,\n",
    "                          W, \n",
    "                          synapse_order(tokenizer, s, W, vocab_size)[0], \n",
    "                          tokenizer)\n",
    "for neuron in tw:\n",
    "    top_words = ''\n",
    "    for k,v in neuron.items():\n",
    "        top_words+= f'{k}: ' + ' '.join(v)\n",
    "\n",
    "    print(top_words)\n",
    "    #print(f'Neuron {neuron}:{top_words}')\n",
    "\n",
    "print(f'Algorithm action: {a}')\n",
    "s, r, done, info = env.step(a)\n",
    "print(r)\n",
    "print(f'===========================iteration :{i} Done :[{done}] ===============================') \n",
    "i+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
